import sys

HEADER = """# This file is automatically generated
"""

wordnet_deps = ['raw/wordnet/'+path for path in
    ['wordnet-synset.ttl','wordnet-glossary.ttl',
    'full/wordnet-wordsense-synset-relations.ttl',
    'wordnet-attribute.ttl', 'wordnet-causes.ttl',
    'wordnet-classifiedby.ttl', 'wordnet-entailment.ttl',
    'wordnet-hyponym.ttl', 'wordnet-instances.ttl',
    'wordnet-membermeronym.ttl', 'wordnet-partmeronym.ttl',
    'wordnet-sameverbgroupas.ttl', 'wordnet-similarity.ttl',
    'wordnet-substancemeronym.ttl', 'full/wordnet-antonym.ttl',
    'full/wordnet-derivationallyrelated.ttl',
    'full/wordnet-participleof.ttl',
    'full/wordnet-pertainsto.ttl',
    'full/wordnet-seealso.ttl']]

globalmind_deps = ['raw/globalmind/GMFrame.yaml',
     'raw/globalmind/GMTranslation.yaml',
     'raw/globalmind/GMAssertion.yaml',
     'raw/globalmind/GMUser.yaml',]

from_tar_file = [
 'raw/dbpedia/mappingbased_properties_en.nt',
 'raw/dbpedia/interlanguage_links_en.nt',
 'raw/dbpedia/instance_types_en.nt',
] + \
    ['raw/jmdict/JMdict.xml',] + \
    ['raw/wiktionary/enwiktionary.xml',
    'raw/wiktionary/dewiktionary.xml',
    'raw/wiktionary/jawiktionary.xml',] + \
    ['raw/conceptnet4%s/conceptnet4%s_flat_%s.jsons'%(ext, ext, i)
    for i in range(10) for ext in ['', '_nadya']] + \
    ['raw/conceptnet_zh/conceptnet_zh_part%s.txt'%i
    for i in range(13)] + \
    wordnet_deps + \
    ['raw/verbosity/verbosity.txt',] + \
    ['raw/umbel/umbel.nt',] + \
    globalmind_deps


def add_dep(lines, rule, input, output, extra=None, params=None):
    if isinstance(output, list):
        output = ' '.join(output)
    if isinstance(input, list):
        input = ' '.join(input)
    if extra:
        if isinstance(extra, list):
            extra = ' '.join(extra)
        extrastr = ' | ' + extra
    else:
        extrastr = ''
    build_rule = "build {output}: {rule} {input}{extra}".format(
        output=output, rule=rule, input=input, extra=extrastr
    )
    lines.append(build_rule)
    if params:
        for key, val in params.items():
            lines.append("  {key} = {val}".format(key=key, val=val))
    lines.append("")

def write_ninja_deps(rules_filename='rules.ninja', out=sys.stdout, version='5.3',
        prefix='data/'):

    print(HEADER, file=out)

    with open(rules_filename, encoding='utf-8') as rulesfile:
        print(rulesfile.read(), file=out)

    lines = []

    lines.extend(download_deps(version, prefix))
    lines.extend(unpack_deps(version, prefix))
    lines.extend(parse_jmdict(prefix))
    lines.extend(parse_wiktionary(prefix))
    lines.extend(parse_conceptnet4(prefix))
    lines.extend(parse_ptt_petgame(prefix))
    lines.extend(parse_wordnet(prefix))
    lines.extend(parse_umbel(prefix))
    lines.extend(parse_verbosity(prefix))
    lines.extend(parse_globalmind(prefix))

    print('\n'.join(lines), file=out)

def download_deps(version, prefix):
    lines = []
    output = prefix+'conceptnet5_raw_data_%s.tar.bz2'%version
    url = 'http://conceptnet5.media.mit.edu/downloads/v%s/'%version+output
    add_dep(lines, 'download', '', output, params={'prefix': prefix, 'url': url})
    return lines

#TODO Add other outputs
def unpack_deps(version, prefix):
    lines = []
    input = prefix+'conceptnet5_raw_data_%s.tar.bz2'%version

    output = from_tar_file
    output = [prefix+out for out in output]

    add_dep(lines, 'extract_tar', input, output, params={'prefix': prefix})
    return lines

def parse_jmdict(prefix):
    lines = []
    input = prefix+'raw/jmdict/JMdict.xml'
    output = prefix+'/edges/jmdict/jmdict.msgpack'
    add_dep(lines, 'parse', input, output, params={'filetype': 'jmdict'})
    return lines

def parse_wiktionary(prefix, langs=('en', 'de', 'ja'), slices=20):
    lines = []
    for lang in langs:
        input = prefix+'raw/wiktionary/%swiktionary.xml'%lang
        output_prefix = prefix+'extracted/wiktionary/%s'%lang
        output = [output_prefix+'wiktionary_%02d.msgpack'%i for i in range(slices)]
        add_dep(lines, 'extract_wiktionary', input, output, params={'lang':lang})

        for i, new_input in enumerate(output):
            new_output = prefix+'edges/wiktionary/%s/wiktionary_%02d.msgpack'%(lang, i)
            add_dep(lines, 'parse_wiktionary', new_input, new_output, params={'lang':lang})

    return lines

#parsers both conceptnet4 and conceptnet4 nadya
def parse_conceptnet4(prefix):
    lines = []
    for style in ['conceptnet4', 'conceptnet4_nadya']:
        for i in range(10):
            input = prefix+'raw/%s/%s_flat_%s.jsons'%(style, style, i)
            output = prefix+'edges/%s%s_flat_%s.msgpack'%(style, style, i)
            add_dep(lines, 'parse', input, output, params={'filetype':'conceptnet4'})

    return lines


def parse_ptt_petgame(prefix):
    lines = []
    for i in range(13):
        input = prefix+'raw/conceptnet_zh/conceptnet_zh_part%s.txt'%i
        output = prefix+'edges/conceptnet_zh/conceptnet_zh_part%s.csv'%i
        add_dep(lines, 'parse', input, output, params={'filetype': 'ptt_petgame'})

    return lines

def parse_wordnet(prefix):
    lines = []
    input = [prefix+dep for dep in wordnet_deps]
    output = ['edges/wordnet/wordnet.msgpack', 'sw_map/wordnet.nt']
    output = [prefix+out for out in output]
    params = {'filetype': 'wordnet', 'prefix': prefix+'sw_map', 'dir': prefix+'raw/wordnet'}
    add_dep(lines, 'parse_sw', input, output, params=params)

    return lines

def parse_umbel(prefix):
    lines = []
    input = prefix+'raw/umbel/umbel.nt'
    output = ['edges/umbel/umbel.msgpack', 'sw_map/umbel.nt']
    output = [prefix+out for out in output]
    params = {'filetype': 'umbel', 'prefix': prefix+'sw_map', 'dir':prefix+'raw/umbel'}
    add_dep(lines, 'parse_sw', input, output, params=params)

    return lines

def parse_verbosity(prefix):
    lines = []
    input = prefix+'raw/verbosity/verbosity.txt'
    output = prefix+'edges/verbosity/verbosity.msgpack'
    add_dep(lines, 'parse', input, output, params={'filetype': 'verbosity'})

    return lines

def parse_globalmind(prefix):
    lines = []
    input = [prefix+dep for dep in globalmind_deps]
    output = prefix+'edges/globalmind/globalmind.msgpack'
    add_dep(lines, 'parse', input, output, params={'filetype': 'verbosity'})

    return lines


def convert_to_csv(prefix):
    pass

def main():
    write_ninja_deps(out=open('build.ninja', mode='w'))

if __name__ == '__main__':
    main()
